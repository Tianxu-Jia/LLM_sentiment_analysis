{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The prompt is too long.\n",
    "to do:\n",
    "1. Shorten the prompt\n",
    "2. Apply RAG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\\n    messages = [{\"role\": \"user\", \"content\": prompt}]\\n    response = openai.ChatCompletion.create(\\n        model=model,\\n        messages=messages,\\n        temperature=0, # this is the degree of randomness of the model\\'s output\\n    )\\n    return response.choices[0].message[\"content\"]\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = \"Based in the {tutorial} do the contect sentiment analysis with the context and phrase: {text}\"\n",
    "prompt = PromptTemplate(\n",
    "  template=question_template,\n",
    "  input_variables=[\"tutorial\", \"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial = \"\"\"This is a context based sentiment analysis task. Here is the tutorial for it:\n",
    "<tutorial>\n",
    "Read the phrase from a customer's feedback and the context associated with the phrase to decide the sentiment category for the phrase based on the context. \n",
    "The meaning of \"Phrase\" ande \"Context\" sentiment judgments are below: \n",
    "-Phrase: A free-form customer comment in the survey. \n",
    "-Context: The question asked in the survey which is the context associated with the answered comments from the customer. they are classified into four: “positive”, “neutral”, “suggestion”, and “negative”. \n",
    "\n",
    "Here are the examples of labelling the phrase on the condition of context.\n",
    "1. No Clear Opinion\n",
    "    In all the sub-class sutiation, all phrase are labelled as No Clear Opinion\n",
    "    1) Phrase is purely an observation, description, or a statement of fact;  \n",
    "        <Context: any, Phrase: This was our anniversary weekend get-away.>        \n",
    "        Sentiment: No clear opinion\n",
    "\n",
    "    2) the sentiment is neutral about the product or company.\n",
    "        <Context: Any, Phrase: The product is okay/fine.>        \n",
    "        Sentiment: No clear opinion   \n",
    "\n",
    "    3) If the phrase is not clear but mostly descriptive, or you might need more context.\n",
    "        <Context: Any, Phrase: I say all that to say this.>        \n",
    "        Sentiment: No clear opinion\n",
    "    \n",
    "    4) a question with a neutral tone that don not imply any positive or negative sentiment.\n",
    "        <Context: Any, Phrase: When will the product be released?>        \n",
    "        Sentiment: No clear opinion\n",
    "\n",
    "    \n",
    "    5) The phrase describes the product is not lacking in quality or customers are not experiencing any issues or their expectations are met, \\\n",
    "        sometimes phrases with clear sentiments or in positive context and note the sentiment changes\n",
    "        <Context: Neutral,  Phrase: The cloth is not see-through!>      \n",
    "        Sentiment: No clear opinion  \n",
    "\n",
    "    6) The phrase only contains nouns in neutral context. \n",
    "        <Context: Neutral,   Phrase: Professionalism.>      \n",
    "        Sentiment: No clear opinion\n",
    "    \n",
    "\n",
    "    7) The sign-off language such as “thank you”, “thanks”\n",
    "        <Context: Neutral,  Phrase: Thank you REDACT_NAME>        \n",
    "        Sentiment: No clear opinion\n",
    "\n",
    "    \n",
    "2. Positive:\n",
    "Phrase contains any positive opinion from the customer regarding customer experience. \n",
    "    <Context: Any, Phrase: You delivered on time.>\n",
    "    Sentiment: Positive  \n",
    "\n",
    "\n",
    "3. Strongly Positive\n",
    "    Phrase generally contains a strong tone for positive sentiment.\n",
    "    <Context:Any,  Phrase: Jimmy at the Craps table was AWESOME and a great teacher for this first-timer!>\n",
    "    Sentiment: Strongly positive\n",
    "    \n",
    "4. Negative\n",
    "        <Context:Any,  Phrase: She did not seem to understand the issue or want to.>\n",
    "        Sentiment: Negative\n",
    "        \n",
    "5. Strongly Negative\n",
    "    Phrase generally contains a strong tone for negative sentiment. The modifier like \"very\", \"extremely\", \"really\", \"worst\" or any strong adjective like worst.\n",
    "    <Context:Any, Phrase: I was very disappointed as I had been anticipating enjoying this buffet for a long time.>\n",
    "    Sentiment: Strongly negative\n",
    "\n",
    "\n",
    "6. Mixed Opinion\n",
    "    Phrase contains both positive and negative sentiments. \n",
    "    <Context:Any, Phrase: Even though the restaurant choices were limited, we enjoyed Charlie’s food so much we ate there twice in one day.>\n",
    "    Sentiment: Mixed opinion   \n",
    "\n",
    "7 Suggestion\n",
    "    Phrase contains some specific actions or suggestions that lead to fulfilling the customer's wish/intent.      \n",
    "    <Context:Any,   Phrase: Provide the Spanish mobile app>\n",
    "    Sentiment: Suggestion  \n",
    "\n",
    "    \n",
    "8. Incorrect language or gibberish\n",
    "If the text is not in the correct language or the phrase does not make any sense to you (gibberish),choose \"incorrect language or gibberish\". If the sentence is gibberish but you still can interpret the meaning, choose your best sentiment judgment.   \n",
    "    <Context:Any,  Phrase: jjo>\n",
    "    Sentiment: gibberish    \n",
    "\n",
    "9. Unsure\n",
    "    The text is clear to you but you don’t know how to annotate it, that is the probability of being divided into any category is almost equal\n",
    "</tutorial>\n",
    "\n",
    "Do the context based sentiment analysis, output should one of No Clear Opinion,positive, strongly Positive, negative, strongly Negative, suggestion, mixed Opinion, incorrect Language or Gibberish,and Unsure.\n",
    "\n",
    "The context and phrase: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "       <Context:Any, Phrase: It would be good to have free shipping when I spend more than $50.>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4329"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # Load the locally downloaded model here\n",
    "    llm = CTransformers(\n",
    "        #model = \"/home/txjia/work/freelance_demo/models/codellama-7b-instruct.ggmlv3.Q4_0.bin\",\n",
    "        #model = \"/home/txjia/work/freelance_demo/models/llama-2-7b.ggmlv3.q2_K.bin\",\n",
    "        model = \"/home/txjia/work/freelance_demo/models/llama-2-7b-chat.ggmlv3.q2_K.bin\",\n",
    "        model_type=\"llama\",\n",
    "        max_new_tokens = 16000,\n",
    "        temperature = 0.2,\n",
    "        repetition_penalty = 1.13\n",
    "        #stream=True\n",
    "        #gpu_layers = 10\n",
    "    )\n",
    "\n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "llm = load_model()\n",
    "llmchain = chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (1327) exceeded maximum context length (512).\n",
      "Number of tokens (1328) exceeded maximum context length (512).\n",
      "Number of tokens (1329) exceeded maximum context length (512).\n",
      "Number of tokens (1330) exceeded maximum context length (512).\n",
      "Number of tokens (1331) exceeded maximum context length (512).\n",
      "Number of tokens (1332) exceeded maximum context length (512).\n",
      "Number of tokens (1333) exceeded maximum context length (512).\n",
      "Number of tokens (1334) exceeded maximum context length (512).\n",
      "Number of tokens (1335) exceeded maximum context length (512).\n",
      "Number of tokens (1336) exceeded maximum context length (512).\n",
      "Number of tokens (1337) exceeded maximum context length (512).\n",
      "Number of tokens (1338) exceeded maximum context length (512).\n",
      "Number of tokens (1339) exceeded maximum context length (512).\n",
      "Number of tokens (1340) exceeded maximum context length (512).\n",
      "Number of tokens (1341) exceeded maximum context length (512).\n",
      "Number of tokens (1342) exceeded maximum context length (512).\n",
      "Number of tokens (1343) exceeded maximum context length (512).\n",
      "Number of tokens (1344) exceeded maximum context length (512).\n",
      "Number of tokens (1345) exceeded maximum context length (512).\n",
      "Number of tokens (1346) exceeded maximum context length (512).\n",
      "Number of tokens (1347) exceeded maximum context length (512).\n",
      "Number of tokens (1348) exceeded maximum context length (512).\n",
      "Number of tokens (1349) exceeded maximum context length (512).\n",
      "Number of tokens (1350) exceeded maximum context length (512).\n",
      "Number of tokens (1351) exceeded maximum context length (512).\n",
      "Number of tokens (1352) exceeded maximum context length (512).\n",
      "Number of tokens (1353) exceeded maximum context length (512).\n",
      "Number of tokens (1354) exceeded maximum context length (512).\n",
      "Number of tokens (1355) exceeded maximum context length (512).\n",
      "Number of tokens (1356) exceeded maximum context length (512).\n",
      "Number of tokens (1357) exceeded maximum context length (512).\n",
      "Number of tokens (1358) exceeded maximum context length (512).\n",
      "Number of tokens (1359) exceeded maximum context length (512).\n",
      "Number of tokens (1360) exceeded maximum context length (512).\n",
      "Number of tokens (1361) exceeded maximum context length (512).\n",
      "Number of tokens (1362) exceeded maximum context length (512).\n",
      "Number of tokens (1363) exceeded maximum context length (512).\n",
      "Number of tokens (1364) exceeded maximum context length (512).\n",
      "Number of tokens (1365) exceeded maximum context length (512).\n",
      "Number of tokens (1366) exceeded maximum context length (512).\n",
      "Number of tokens (1367) exceeded maximum context length (512).\n",
      "Number of tokens (1368) exceeded maximum context length (512).\n",
      "Number of tokens (1369) exceeded maximum context length (512).\n",
      "Number of tokens (1370) exceeded maximum context length (512).\n",
      "Number of tokens (1371) exceeded maximum context length (512).\n",
      "Number of tokens (1372) exceeded maximum context length (512).\n",
      "Number of tokens (1373) exceeded maximum context length (512).\n",
      "Number of tokens (1374) exceeded maximum context length (512).\n",
      "Number of tokens (1375) exceeded maximum context length (512).\n",
      "Number of tokens (1376) exceeded maximum context length (512).\n",
      "Number of tokens (1377) exceeded maximum context length (512).\n",
      "Number of tokens (1378) exceeded maximum context length (512).\n",
      "Number of tokens (1379) exceeded maximum context length (512).\n",
      "Number of tokens (1380) exceeded maximum context length (512).\n",
      "Number of tokens (1381) exceeded maximum context length (512).\n",
      "Number of tokens (1382) exceeded maximum context length (512).\n",
      "Number of tokens (1383) exceeded maximum context length (512).\n",
      "Number of tokens (1384) exceeded maximum context length (512).\n",
      "Number of tokens (1385) exceeded maximum context length (512).\n",
      "Number of tokens (1386) exceeded maximum context length (512).\n",
      "Number of tokens (1387) exceeded maximum context length (512).\n",
      "Number of tokens (1388) exceeded maximum context length (512).\n",
      "Number of tokens (1389) exceeded maximum context length (512).\n",
      "Number of tokens (1390) exceeded maximum context length (512).\n",
      "Number of tokens (1391) exceeded maximum context length (512).\n",
      "Number of tokens (1392) exceeded maximum context length (512).\n",
      "Number of tokens (1393) exceeded maximum context length (512).\n",
      "Number of tokens (1394) exceeded maximum context length (512).\n",
      "Number of tokens (1395) exceeded maximum context length (512).\n",
      "Number of tokens (1396) exceeded maximum context length (512).\n",
      "Number of tokens (1397) exceeded maximum context length (512).\n",
      "Number of tokens (1398) exceeded maximum context length (512).\n",
      "Number of tokens (1399) exceeded maximum context length (512).\n",
      "Number of tokens (1400) exceeded maximum context length (512).\n",
      "Number of tokens (1401) exceeded maximum context length (512).\n",
      "Number of tokens (1402) exceeded maximum context length (512).\n",
      "Number of tokens (1403) exceeded maximum context length (512).\n",
      "Number of tokens (1404) exceeded maximum context length (512).\n",
      "Number of tokens (1405) exceeded maximum context length (512).\n",
      "Number of tokens (1406) exceeded maximum context length (512).\n",
      "Number of tokens (1407) exceeded maximum context length (512).\n",
      "Number of tokens (1408) exceeded maximum context length (512).\n",
      "Number of tokens (1409) exceeded maximum context length (512).\n",
      "Number of tokens (1410) exceeded maximum context length (512).\n",
      "Number of tokens (1411) exceeded maximum context length (512).\n",
      "Number of tokens (1412) exceeded maximum context length (512).\n",
      "Number of tokens (1413) exceeded maximum context length (512).\n",
      "Number of tokens (1414) exceeded maximum context length (512).\n",
      "Number of tokens (1415) exceeded maximum context length (512).\n",
      "Number of tokens (1416) exceeded maximum context length (512).\n",
      "Number of tokens (1417) exceeded maximum context length (512).\n",
      "Number of tokens (1418) exceeded maximum context length (512).\n",
      "Number of tokens (1419) exceeded maximum context length (512).\n",
      "Number of tokens (1420) exceeded maximum context length (512).\n",
      "Number of tokens (1421) exceeded maximum context length (512).\n",
      "Number of tokens (1422) exceeded maximum context length (512).\n",
      "Number of tokens (1423) exceeded maximum context length (512).\n",
      "Number of tokens (1424) exceeded maximum context length (512).\n",
      "Number of tokens (1425) exceeded maximum context length (512).\n",
      "Number of tokens (1426) exceeded maximum context length (512).\n",
      "Number of tokens (1427) exceeded maximum context length (512).\n",
      "Number of tokens (1428) exceeded maximum context length (512).\n",
      "Number of tokens (1429) exceeded maximum context length (512).\n",
      "Number of tokens (1430) exceeded maximum context length (512).\n",
      "Number of tokens (1431) exceeded maximum context length (512).\n",
      "Number of tokens (1432) exceeded maximum context length (512).\n",
      "Number of tokens (1433) exceeded maximum context length (512).\n",
      "Number of tokens (1434) exceeded maximum context length (512).\n",
      "Number of tokens (1435) exceeded maximum context length (512).\n",
      "Number of tokens (1436) exceeded maximum context length (512).\n",
      "Number of tokens (1437) exceeded maximum context length (512).\n",
      "Number of tokens (1438) exceeded maximum context length (512).\n",
      "Number of tokens (1439) exceeded maximum context length (512).\n",
      "Number of tokens (1440) exceeded maximum context length (512).\n",
      "Number of tokens (1441) exceeded maximum context length (512).\n",
      "Number of tokens (1442) exceeded maximum context length (512).\n",
      "Number of tokens (1443) exceeded maximum context length (512).\n",
      "Number of tokens (1444) exceeded maximum context length (512).\n",
      "Number of tokens (1445) exceeded maximum context length (512).\n",
      "Number of tokens (1446) exceeded maximum context length (512).\n",
      "Number of tokens (1447) exceeded maximum context length (512).\n",
      "Number of tokens (1448) exceeded maximum context length (512).\n",
      "Number of tokens (1449) exceeded maximum context length (512).\n",
      "Number of tokens (1450) exceeded maximum context length (512).\n",
      "Number of tokens (1451) exceeded maximum context length (512).\n",
      "Number of tokens (1452) exceeded maximum context length (512).\n",
      "Number of tokens (1453) exceeded maximum context length (512).\n",
      "Number of tokens (1454) exceeded maximum context length (512).\n",
      "Number of tokens (1455) exceeded maximum context length (512).\n",
      "Number of tokens (1456) exceeded maximum context length (512).\n",
      "Number of tokens (1457) exceeded maximum context length (512).\n",
      "Number of tokens (1458) exceeded maximum context length (512).\n",
      "Number of tokens (1459) exceeded maximum context length (512).\n",
      "Number of tokens (1460) exceeded maximum context length (512).\n",
      "Number of tokens (1461) exceeded maximum context length (512).\n",
      "Number of tokens (1462) exceeded maximum context length (512).\n",
      "Number of tokens (1463) exceeded maximum context length (512).\n",
      "Number of tokens (1464) exceeded maximum context length (512).\n",
      "Number of tokens (1465) exceeded maximum context length (512).\n",
      "Number of tokens (1466) exceeded maximum context length (512).\n",
      "Number of tokens (1467) exceeded maximum context length (512).\n",
      "Number of tokens (1468) exceeded maximum context length (512).\n",
      "Number of tokens (1469) exceeded maximum context length (512).\n",
      "Number of tokens (1470) exceeded maximum context length (512).\n",
      "Number of tokens (1471) exceeded maximum context length (512).\n",
      "Number of tokens (1472) exceeded maximum context length (512).\n",
      "Number of tokens (1473) exceeded maximum context length (512).\n",
      "Number of tokens (1474) exceeded maximum context length (512).\n",
      "Number of tokens (1475) exceeded maximum context length (512).\n",
      "Number of tokens (1476) exceeded maximum context length (512).\n",
      "Number of tokens (1477) exceeded maximum context length (512).\n",
      "Number of tokens (1478) exceeded maximum context length (512).\n",
      "Number of tokens (1479) exceeded maximum context length (512).\n",
      "Number of tokens (1480) exceeded maximum context length (512).\n",
      "Number of tokens (1481) exceeded maximum context length (512).\n",
      "Number of tokens (1482) exceeded maximum context length (512).\n",
      "Number of tokens (1483) exceeded maximum context length (512).\n",
      "Number of tokens (1484) exceeded maximum context length (512).\n",
      "Number of tokens (1485) exceeded maximum context length (512).\n",
      "Number of tokens (1486) exceeded maximum context length (512).\n",
      "Number of tokens (1487) exceeded maximum context length (512).\n",
      "Number of tokens (1488) exceeded maximum context length (512).\n",
      "Number of tokens (1489) exceeded maximum context length (512).\n",
      "Number of tokens (1490) exceeded maximum context length (512).\n",
      "Number of tokens (1491) exceeded maximum context length (512).\n",
      "Number of tokens (1492) exceeded maximum context length (512).\n",
      "Number of tokens (1493) exceeded maximum context length (512).\n",
      "Number of tokens (1494) exceeded maximum context length (512).\n",
      "Number of tokens (1495) exceeded maximum context length (512).\n",
      "Number of tokens (1496) exceeded maximum context length (512).\n",
      "Number of tokens (1497) exceeded maximum context length (512).\n",
      "Number of tokens (1498) exceeded maximum context length (512).\n",
      "Number of tokens (1499) exceeded maximum context length (512).\n",
      "Number of tokens (1500) exceeded maximum context length (512).\n",
      "Number of tokens (1501) exceeded maximum context length (512).\n",
      "Number of tokens (1502) exceeded maximum context length (512).\n",
      "Number of tokens (1503) exceeded maximum context length (512).\n",
      "Number of tokens (1504) exceeded maximum context length (512).\n",
      "Number of tokens (1505) exceeded maximum context length (512).\n",
      "Number of tokens (1506) exceeded maximum context length (512).\n",
      "Number of tokens (1507) exceeded maximum context length (512).\n",
      "Number of tokens (1508) exceeded maximum context length (512).\n",
      "Number of tokens (1509) exceeded maximum context length (512).\n",
      "Number of tokens (1510) exceeded maximum context length (512).\n",
      "Number of tokens (1511) exceeded maximum context length (512).\n",
      "Number of tokens (1512) exceeded maximum context length (512).\n",
      "Number of tokens (1513) exceeded maximum context length (512).\n",
      "Number of tokens (1514) exceeded maximum context length (512).\n",
      "Number of tokens (1515) exceeded maximum context length (512).\n",
      "Number of tokens (1516) exceeded maximum context length (512).\n",
      "Number of tokens (1517) exceeded maximum context length (512).\n",
      "Number of tokens (1518) exceeded maximum context length (512).\n",
      "Number of tokens (1519) exceeded maximum context length (512).\n",
      "Number of tokens (1520) exceeded maximum context length (512).\n",
      "Number of tokens (1521) exceeded maximum context length (512).\n",
      "Number of tokens (1522) exceeded maximum context length (512).\n",
      "Number of tokens (1523) exceeded maximum context length (512).\n",
      "Number of tokens (1524) exceeded maximum context length (512).\n",
      "Number of tokens (1525) exceeded maximum context length (512).\n",
      "Number of tokens (1526) exceeded maximum context length (512).\n",
      "Number of tokens (1527) exceeded maximum context length (512).\n",
      "Number of tokens (1528) exceeded maximum context length (512).\n",
      "Number of tokens (1529) exceeded maximum context length (512).\n",
      "Number of tokens (1530) exceeded maximum context length (512).\n",
      "Number of tokens (1531) exceeded maximum context length (512).\n",
      "Number of tokens (1532) exceeded maximum context length (512).\n",
      "Number of tokens (1533) exceeded maximum context length (512).\n",
      "Number of tokens (1534) exceeded maximum context length (512).\n",
      "Number of tokens (1535) exceeded maximum context length (512).\n",
      "Number of tokens (1536) exceeded maximum context length (512).\n",
      "Number of tokens (1537) exceeded maximum context length (512).\n",
      "Number of tokens (1538) exceeded maximum context length (512).\n",
      "Number of tokens (1539) exceeded maximum context length (512).\n",
      "Number of tokens (1540) exceeded maximum context length (512).\n",
      "Number of tokens (1541) exceeded maximum context length (512).\n",
      "Number of tokens (1542) exceeded maximum context length (512).\n",
      "Number of tokens (1543) exceeded maximum context length (512).\n",
      "Number of tokens (1544) exceeded maximum context length (512).\n",
      "Number of tokens (1545) exceeded maximum context length (512).\n",
      "Number of tokens (1546) exceeded maximum context length (512).\n",
      "Number of tokens (1547) exceeded maximum context length (512).\n",
      "Number of tokens (1548) exceeded maximum context length (512).\n",
      "Number of tokens (1549) exceeded maximum context length (512).\n",
      "Number of tokens (1550) exceeded maximum context length (512).\n",
      "Number of tokens (1551) exceeded maximum context length (512).\n",
      "Number of tokens (1552) exceeded maximum context length (512).\n",
      "Number of tokens (1553) exceeded maximum context length (512).\n",
      "Number of tokens (1554) exceeded maximum context length (512).\n",
      "Number of tokens (1555) exceeded maximum context length (512).\n",
      "Number of tokens (1556) exceeded maximum context length (512).\n",
      "Number of tokens (1557) exceeded maximum context length (512).\n",
      "Number of tokens (1558) exceeded maximum context length (512).\n",
      "Number of tokens (1559) exceeded maximum context length (512).\n",
      "Number of tokens (1560) exceeded maximum context length (512).\n",
      "Number of tokens (1561) exceeded maximum context length (512).\n",
      "Number of tokens (1562) exceeded maximum context length (512).\n",
      "Number of tokens (1563) exceeded maximum context length (512).\n",
      "Number of tokens (1564) exceeded maximum context length (512).\n",
      "Number of tokens (1565) exceeded maximum context length (512).\n",
      "Number of tokens (1566) exceeded maximum context length (512).\n",
      "Number of tokens (1567) exceeded maximum context length (512).\n",
      "Number of tokens (1568) exceeded maximum context length (512).\n",
      "Number of tokens (1569) exceeded maximum context length (512).\n",
      "Number of tokens (1570) exceeded maximum context length (512).\n",
      "Number of tokens (1571) exceeded maximum context length (512).\n",
      "Number of tokens (1572) exceeded maximum context length (512).\n",
      "Number of tokens (1573) exceeded maximum context length (512).\n",
      "Number of tokens (1574) exceeded maximum context length (512).\n",
      "Number of tokens (1575) exceeded maximum context length (512).\n",
      "Number of tokens (1576) exceeded maximum context length (512).\n",
      "Number of tokens (1577) exceeded maximum context length (512).\n",
      "Number of tokens (1578) exceeded maximum context length (512).\n",
      "Number of tokens (1579) exceeded maximum context length (512).\n",
      "Number of tokens (1580) exceeded maximum context length (512).\n",
      "Number of tokens (1581) exceeded maximum context length (512).\n",
      "Number of tokens (1582) exceeded maximum context length (512).\n",
      "Number of tokens (1583) exceeded maximum context length (512).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n        Sentiment: \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n        \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n        Sentiment:        \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n       \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmchain.run(tutorial=tutorial, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
